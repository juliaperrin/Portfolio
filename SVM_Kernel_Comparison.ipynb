{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f2ab04",
   "metadata": {},
   "source": [
    "# SVM Kernel Comparison Project\n",
    "\n",
    "This project evaluates and compares the performance of Support Vector Machine (SVM) classifiers using different kernel functions on a synthetic dataset. The goal is to understand how various kernels influence classification boundaries and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c463657d",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "A synthetic dataset with two input features (`X1` and `X2`) and a binary class label was utilized. This allows clear visualization of how SVM decision boundaries change across kernel types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355aee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d562c44",
   "metadata": {},
   "source": [
    "## Data Generation and Preprocessing\n",
    "\n",
    "The dataset was generated using `make_classification`, followed by splitting into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=300, n_features=2, n_informative=2, n_redundant=0,\n",
    "                           n_clusters_per_class=1, flip_y=0.1, class_sep=1.0, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=ListedColormap(['red', 'blue']), edgecolor='k')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Training Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4144c",
   "metadata": {},
   "source": [
    "## SVM Model Training and Comparison\n",
    "\n",
    "Four different SVM kernels were used: linear, polynomial, RBF, and sigmoid. Each model was trained and evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44031718",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "models = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = SVC(kernel=kernel, gamma='auto')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    models[kernel] = (model, acc)\n",
    "    print(f\"{kernel.capitalize()} Kernel Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebff9c",
   "metadata": {},
   "source": [
    "## Visualization of Decision Boundaries\n",
    "\n",
    "The following plots illustrate the decision boundaries for each kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823933e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title):\n",
    "    h = .02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.contourf(xx, yy, Z, cmap=ListedColormap(['#FFAAAA', '#AAAAFF']), alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=ListedColormap(['red', 'blue']), edgecolor='k')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2581dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kernel in kernels:\n",
    "    model, _ = models[kernel]\n",
    "    plot_decision_boundary(model, X_train, y_train, f\"SVM with {kernel.capitalize()} Kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70beb1b6",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project highlights the importance of kernel selection in Support Vector Machines. While linear kernels produce simple decision boundaries, nonlinear kernels like RBF and polynomial allow for more flexibility in separating complex data. The visualizations and accuracy scores provide insights into each kernel's strengths in classification tasks."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
